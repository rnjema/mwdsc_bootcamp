{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Large \\text{Web Scraping for Data Science - Ralph Tambala}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## What is Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Web scraping is a process of automating the extraction of data in an efficient and fast way from the web. With the help of web scraping, you can extract data from any website, no matter how large is the data, on your computer.\n",
    "\n",
    "On the other hand, APIs give you direct access to the data you want."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Why Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Cost-effective**\n",
    "\n",
    "Web scraping services provide an essential service at a competitive cost. The data will have to be collected back from websites and analyzed so that the internet functions regularly.\n",
    "\n",
    "**Data accuracy**\n",
    "\n",
    "Simple errors in data extraction can lead to major issues. Hence it is needed to ensure that the data is correct. Data scraping is not only a fast process, but its accurate too.\n",
    "\n",
    "**Easy to implement**\n",
    "\n",
    "Once a website scraping service starts collecting data, you can rest assured that you are getting data from not just a single page but from the whole domain. With a one time investment, it can have a high volume of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Challenges of Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Data analysis of data retrieved**\n",
    "\n",
    "Data need to be treated first, before it can be analysed. This often becomes a time-consuming work.\n",
    "\n",
    "**Difficult to analyze**\n",
    "\n",
    "For those who are not much into programming, web scrapers can be confusing.\n",
    "\n",
    "**Speed and protection policies**\n",
    "\n",
    "Most of the web scraping services are slower than API calls. Also many websites do not allow screen scraping. Also, if any code of the target website gets changed, web scrapers stops capture the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## HTML Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hypertext Markup Language, a standardized system for tagging text files to achieve font, colour, graphic, and hyperlink effects on World Wide Web pages.\n",
    "\n",
    "I have provided a sample HTML file for a quick summary of what HTML is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Steps Involved in Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Install 3rd party libraries\n",
    "2. Access the HTML content from webpage\n",
    "3. Parse the HTML content\n",
    "4. Prepare for your data science project\n",
    "5. Data cleaning\n",
    "5. Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Step 1: Install the required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will install the following libraries:\n",
    "- <code>requests</code>: allows us to send HTTP/1.1 requests using Python.\n",
    "- <code>html5lib</code>: it is a pure-python library for parsing HTML. It is designed to conform to the WHATWG HTML specification, as is implemented by all major web browsers. *(The Web Hypertext Application Technology Working Group (WHATWG) is a community of people interested in evolving HTML and related technologies. The WHATWG was founded by individuals from Apple Inc., the Mozilla Foundation and Opera Software, leading Web browser vendors, in 2004.)*\n",
    "- <code>bs4</code>: bs4 is an acronym for Beautiful Soup. Beautiful Soup is a library for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags). It creates a parse tree for parsed pages that can be used to extract data from HTML.\n",
    "\n",
    "These libraries can be installed using pip as shown below or one can manually and install them using links above\n",
    "\n",
    "    pip install requests\n",
    "    pip install html5lib # lxml, bleach, etc\n",
    "    pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Step 2: Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import html5lib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Step 3: Accessing the HTML content from webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Specify the URL of the webpage\n",
    "2. Send a HTTP request to the specified URL and save the response from server\n",
    "3. Check if response is OK - 200\n",
    "4. If OK, then print raw content of the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# here's the URL of interest\n",
    "url = \"https://en.wikipedia.org/wiki/Template:COVID-19_pandemic_data/Malawi_medical_cases_chart\"\n",
    "# we use get to send the requests and stores the result\n",
    "response = requests.get(url)\n",
    "# now we check if the webpage was returned successfully\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Status codes**\n",
    "- 200: The HTTP 200 *OK success* status response code indicates that the request has succeeded.\n",
    "- 404: The HTTP 404, 404 not found, 404, 404 error, *page not found* or file not found error message is a hypertext transfer protocol (HTTP) standard response code, in computer network communications, to indicate that the browser was able to communicate with a given server, but the server could not find what was requested.\n",
    "- 400: The HTTP 400 *Bad Request response* status code indicates that the server cannot or will not process the request due to something that is perceived to be a client error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, let's view the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# let's print the raw HTML content\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Step 3: Parse the HTML content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We create a Beautiful Soup object to represent the parsed document as a whole. For most purposes, you can treat it as a Tag object. This means it supports most of the methods described in Navigating the tree and Searching the HTML tree.\n",
    "\n",
    "A BeautifulSoup object can be created by passing two arguments:\n",
    "- <code>response.text</code>: It is the raw HTML content\n",
    "- <code>html5lib</code>: It is a pure-python library for parsing HTML\n",
    "\n",
    "<code>soup.prettify()</code> is used to get the visual representation of the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html5lib')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Step 4: Searching and navigating through the parse tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To extract the data of interest to us we will need to navigate through the nested structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# use find() to capture first p with class course-listing-title\n",
    "block = soup.find('tr', class_ = 'mw-collapsible')\n",
    "block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# capture all p with class class course-listing-title\n",
    "table = soup.find_all('tr', class_ = 'mw-collapsible')\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for item in table:\n",
    "    key = item.find('td', {'class':'bb-c', 'colspan':'2'}).text\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for item in table:\n",
    "    key = item.find('td', {'class':'bb-c', 'colspan':'2'}).text\n",
    "    total_cases = item.find('span', {'class':'mcc-rw'}).text\n",
    "    print('Date: {}\\t\\tTotal Cases: {}'.format(key, total_cases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dates = []\n",
    "cases = []\n",
    "deaths = []\n",
    "for item in table:\n",
    "    date = item.find('td', {'class':'bb-c', 'colspan':'2'}).text\n",
    "\n",
    "    cases_and_deaths = item.find_all('span', {'class':'mcc-rw'})\n",
    "    if len(cases_and_deaths) == 2:\n",
    "        total_cases = cases_and_deaths[0].text\n",
    "        total_deaths = cases_and_deaths[1].text\n",
    "    else:\n",
    "        total_cases = cases_and_deaths[0].text\n",
    "        total_deaths = 0\n",
    "    \n",
    "    dates.append(date)\n",
    "    cases.append(total_cases)\n",
    "    deaths.append(total_deaths)\n",
    "    #print('Date: {}\\t\\tTotal Cases: {}\\t\\t Deaths: {}'.format(date, total_cases, total_deaths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Step 5: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cleaned_total_cases = []\n",
    "for item in cases:\n",
    "    cleaned_total_cases.append(int(str(item).replace(',','')))\n",
    "    \n",
    "cleaned_total_deaths = []\n",
    "for item in deaths:\n",
    "    cleaned_total_deaths.append(int(str(item).replace(',','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Date':pd.Series(dates), 'Total Cases':pd.Series(cleaned_total_cases), 'Total Deaths':pd.Series(cleaned_total_deaths)})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[df['Date'] == '⋮'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df[df['Date'] == '⋮']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "missing_dates = df.index[df['Date'] == '⋮'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.drop(index=missing_dates, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will do some simple visualizations just to appreciate what we have achieved so far!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base = alt.Chart(df[:120]).mark_bar().encode(\n",
    "    x='monthdate(Date):O',\n",
    ").properties(\n",
    "    width=420,\n",
    "    height=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "red = alt.value('#f54242')\n",
    "base.encode(y='Total Cases').properties(title='Total Confirmed') | base.encode(color=red, y='Total Deaths').properties(title='Total deaths') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will add some new columns that may be useful. In this case, new cases confirmed and new deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['New Cases'] = df['Total Cases'] - df['Total Cases'].shift(1).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['New Deaths'] = df['Total Deaths'] - df['Total Deaths'].shift(1).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df[['Date', 'New Cases', 'New Deaths', 'Total Cases', 'Total Deaths']]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['New Cases'] = pd.to_numeric(df['New Cases'])\n",
    "df['New Deaths'] = pd.to_numeric(df['New Deaths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "base = alt.Chart(df[:120]).mark_bar().encode(\n",
    "    x='monthdate(Date):O',\n",
    ").properties(\n",
    "    width=420,\n",
    "    height=200\n",
    ")\n",
    "\n",
    "base.encode(y='New Cases').properties(title='New confirmed') | base.encode(color=red, y='New Deaths').properties(title='New deaths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Step 6: Saving to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Finally, we can save the dataframe into a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('malawi_covid_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La fin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
